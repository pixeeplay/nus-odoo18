<?xml version="1.0" encoding="utf-8"?>
<odoo>
    <data noupdate="1">
        <!-- Default Ollama configuration -->
        <record id="ollama_config_default" model="ollama.config">
            <field name="name">Ollama Local</field>
            <field name="provider">ollama</field>
            <field name="base_url">http://localhost:11434</field>
            <field name="api_endpoint">/api/chat</field>
            <field name="ollama_api_mode">native</field>
            <field name="ai_model_name">llama3.2</field>
            <field name="max_tokens">2000</field>
            <field name="temperature">0.7</field>
            <field name="ollama_num_ctx">4096</field>
            <field name="ollama_num_gpu">99</field>
            <field name="ollama_keep_alive">10m</field>
            <field name="ollama_request_timeout">180</field>
            <field name="ollama_parallel_workers">2</field>
            <field name="is_default" eval="True"/>
            <field name="active" eval="True"/>
        </record>
    </data>
</odoo>
